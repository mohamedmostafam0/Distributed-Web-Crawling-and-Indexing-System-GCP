# src/scripts/.env.example
# Copy this file to .env and fill in your actual configuration values.
# Do NOT commit the .env file with sensitive information.

# --- GCP Configuration ---
GCP_PROJECT_ID="sunlit-pixel-456910-j0"

# --- Pub/Sub Configuration ---

# UI
NEW_CRAWL_JOB_TOPIC_ID="UI-master"


# Master Node
CRAWL_TASKS_TOPIC_ID="UI-master-sub"

# Crawler Node
CRAWL_TASKS_SUBSCRIPTION_ID="Master-Crawler-sub" # Subscription for crawl tasks
INDEX_QUEUE_TOPIC_ID="Crawler-Indexer-sub"

# Optional: Separate topic for new URLs, otherwise defaults to CRAWL_TASKS_TOPIC_ID
# NEW_URL_TASKS_TOPIC_ID="your-new-urls-topic"

# Indexer Node
INDEX_QUEUE_SUBSCRIPTION_ID="Crawler-Indexer-sub" # Subscription for index tasks

# --- Google Cloud Storage ---
GCS_BUCKET_NAME="webcrawlingproject" # Should match output from Terraform
SEED_FILE_PATH="seeds/start_urls.txt" # Path within GCS bucket for seed URLs

# --- Crawler Configuration ---
MAX_DEPTH="6" # Max crawl depth (integer)

# --- Indexer Configuration ---
# Example for Elasticsearch
ES_HOST=elasticsearch.default.svc.cluster.local  # Or your VM/hostname
ES_PORT=9200
ES_INDEX_NAME=webcrawler_index

# --- Optional: Node Identification ---
# HOSTNAME can often be automatically detected, but can be set explicitly if needed
# HOSTNAME="node-xyz"