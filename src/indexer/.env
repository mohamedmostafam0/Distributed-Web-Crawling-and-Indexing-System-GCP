# src/scripts/.env.example
# Copy this file to .env and fill in your actual configuration values.
# Do NOT commit the .env file with sensitive information.

# --- GCP Configuration ---
GCP_PROJECT_ID="sunlit-pixel-456910-j0"

# --- Pub/Sub Configuration ---

# UI
NEW_CRAWL_JOB_TOPIC_ID="UI-Master"


# Master Node
CRAWL_TASKS_TOPIC_ID="Master-Crawler"
NEW_MASTER_JOB_SUBSCRIPTION_ID="UI-Master-sub" # Subscription for new crawl jobs

# Crawler Node
INDEX_QUEUE_TOPIC_ID="Crawler-Indexer"
NEW_CRAWL_JOB_SUBSCRIPTION_ID="Master-Crawler-sub"
NEW_URL_TASKS_TOPIC_ID="UI-Master"

# Optional: Separate topic for new URLs, otherwise defaults to CRAWL_TASKS_TOPIC_ID
# NEW_URL_TASKS_TOPIC_ID="your-new-urls-topic"

# Indexer Node
INDEX_QUEUE_SUBSCRIPTION_ID="Crawler-Indexer-sub" # Subscription for index tasks
ES_HOST="ac3560e97e724345bad0ec24db111398.me-west1.gcp.elastic-cloud.com"
ES_PORT=443
ES_INDEX_NAME="2508592824"
ES_USERNAME="elastic"
ES_PASSWORD="DistributedProject31_"



# --- Google Cloud Storage ---
GCS_BUCKET_NAME="webcrawlingproject" # Should match output from Terraform
SEED_FILE_PATH="seeds/start_urls.txt" # Path within GCS bucket for seed URLs

# --- Crawler Configuration ---
MAX_DEPTH="6" # Max crawl depth (integer)

# --- Indexer Configuration ---
# Example for Whoosh (Ensure this directory is mounted from persistent disk)
INDEX_DIR="/data/index"
# Example for Elasticsearch

# --- Optional: Node Identification ---
# HOSTNAME can often be automatically detected, but can be set explicitly if needed
# HOSTNAME="node-xyz"